{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ngu\\mambaforge\\envs\\ml_env\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\Ngu\\mambaforge\\envs\\ml_env\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset, TensorDataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../data\n",
       "    Split: Train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../data\n",
       "    Split: Test"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = MNIST(root=\"../data\", train=True, download=True)\n",
    "test_ds = MNIST(root=\"../data\", train=False, download=True)\n",
    "display(train_ds)\n",
    "display(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  50000\n",
      "Val size:  10000\n",
      "Test size:  10000\n"
     ]
    }
   ],
   "source": [
    "# Splitting to train and valid\n",
    "train_ds, val_ds = random_split(train_ds, [50000, 10000])\n",
    "print(\"Train size: \", len(train_ds))\n",
    "print(\"Val size: \", len(val_ds))\n",
    "print(\"Test size: \", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "I will replicate the grayscale image 3 times to create a 3-channel image. This is because our pretrained model expects 3-channel images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, ds, transform=None):\n",
    "        self.ds = ds\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.ds[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    v2.ToImageTensor(), v2.ConvertDtype(),\n",
    "    v2.Lambda(lambda x: torch.cat([x, x, x], 0))\n",
    "])\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.ToImageTensor(), v2.ConvertDtype(),\n",
    "    v2.Lambda(lambda x: torch.cat([x, x, x], 0))\n",
    "])\n",
    "\n",
    "test_transform = val_transform\n",
    "\n",
    "train_ds = MyDataset(train_ds, train_transform)\n",
    "val_ds = MyDataset(val_ds, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(8, 3))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_ds[i]\n",
    "    ax.imshow(image.squeeze().permute(1, 2, 0), cmap='gray')\n",
    "    ax.set_title(label)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: ResNet18 architecture\n",
    "\n",
    "We fine-tune a ResNet18 model, trained on ImageNet. Other models might be used, but for the purpose of this notebook a ResNet18 is a good trade-off between training time and model accuracy.\n",
    "The model originally has a 512-dimensional output layer, but our dataset has only 10 classes, so we remove the output layer and define a new Fully-Connected layer with just 10 neurons, one for each class in CIFAR-10. The parameters of these new neurons are initialized with Xavier initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 10)\n",
    "        torch.nn.init.xavier_uniform_(self.model.fc.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fine-tuning, the model parameters of the network body are trained using a lower learning rate than for the head, since for the latter we have to train them from scratch. We rely on Parameter Groups from PyTorch to define two learning rates for the two groups, and use Adam optimizer with weight_decay = 5e-4 (find via hyperparameter search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ngu\\mambaforge\\envs\\ml_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ngu\\mambaforge\\envs\\ml_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "lr, weight_decay = 1e-5, 5e-4\n",
    "\n",
    "model = ResNet()\n",
    "model.to(device)\n",
    "\n",
    "params_1x = [param for name, param in model.named_parameters() if 'fc' not in str(name)]\n",
    "opt = torch.optim.Adam([{'params': params_1x}, {'params': model.model.fc.parameters(), 'lr': lr * 10}], lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y_true): \n",
    "    return (torch.argmax(preds, dim=1) == y_true).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [11:09<1:40:24, 669.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10],  Train loss: 1.2061,  Train acc: 0.6217,  Val loss: 0.3465,  Val acc: 0.8932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [22:28<1:29:59, 674.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10],  Train loss: 0.4173,  Train acc: 0.8684,  Val loss: 0.1399,  Val acc: 0.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [34:09<1:20:08, 686.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10],  Train loss: 0.2476,  Train acc: 0.9232,  Val loss: 0.0907,  Val acc: 0.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [44:58<1:07:12, 672.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10],  Train loss: 0.1938,  Train acc: 0.9390,  Val loss: 0.0667,  Val acc: 0.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [56:13<56:04, 672.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10],  Train loss: 0.1513,  Train acc: 0.9525,  Val loss: 0.0569,  Val acc: 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [1:06:59<44:15, 663.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10],  Train loss: 0.1262,  Train acc: 0.9612,  Val loss: 0.0534,  Val acc: 0.9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [1:18:08<33:16, 665.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10],  Train loss: 0.1126,  Train acc: 0.9646,  Val loss: 0.0474,  Val acc: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [1:29:10<22:08, 664.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10],  Train loss: 0.0973,  Train acc: 0.9697,  Val loss: 0.0427,  Val acc: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [1:39:12<10:44, 644.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10],  Train loss: 0.0897,  Train acc: 0.9718,  Val loss: 0.0361,  Val acc: 0.9893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:49:27<00:00, 656.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10],  Train loss: 0.0800,  Train acc: 0.9749,  Val loss: 0.0362,  Val acc: 0.9889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 10\n",
    "train_loss, val_loss = [], []\n",
    "train_acc, val_acc = [], []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    model.train()\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        \n",
    "        preds = model(Xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        acc += accuracy(preds, yb)\n",
    "\n",
    "    train_loss.append(epoch_loss / len(train_loader))\n",
    "    train_acc.append(acc / len(train_loader))\n",
    "\n",
    "\n",
    "    epoch_loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            \n",
    "            preds = model(Xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            acc += accuracy(preds, yb)\n",
    "\n",
    "    val_loss.append(epoch_loss / len(val_loader))\n",
    "    val_acc.append(acc / len(val_loader))\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{epochs}], \",\n",
    "        f\"Train loss: {train_loss[-1]:.4f}, \",\n",
    "        f\"Train acc: {train_acc[-1]:.4f}, \",\n",
    "        f\"Val loss: {val_loss[-1]:.4f}, \",\n",
    "        f\"Val acc: {val_acc[-1]:.4f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.stack([test_transform(image) for image in test_ds.data])\n",
    "y_test = test_ds.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9904)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy(model(X_test), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../models/resnet18_finetune.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "tensor(7)\n",
      "tensor([[-6.2363, -0.0404,  0.0223, -4.0056,  0.1797, -2.2600, -3.1522, 11.8789,\n",
      "         -4.0404,  3.0870]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a7cc9ea110>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 0\n",
    "print(y_test[num])\n",
    "print(torch.argmax(model(X_test[num].unsqueeze(0))))\n",
    "print(model(X_test[num].unsqueeze(0)))\n",
    "plt.imshow(X_test[num].squeeze().permute(1, 2, 0), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
